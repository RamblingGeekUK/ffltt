name: Channel Issue to PR

on:
  issues:
    types: [labeled]

permissions:
  contents: write
  issues: write
  pull-requests: write

jobs:
  update-channels-json:
    if: github.event.label.name == 'accepted'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install jq and gh cli
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          sudo apt-get install -y gh

      - name: Parse issue and update channels.json
        id: update
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          export GH_TOKEN="${{ secrets.GITHUB_TOKEN }}"
          ISSUE_NUMBER=${{ github.event.issue.number }}
          gh issue view $ISSUE_NUMBER --json body > issue.json
          BODY=$(jq -r .body issue.json)

          # Debug: Show the raw body first
          echo "RAW BODY:"
          echo "$BODY"
          echo "---"

          # Create a simple parser script
          cat > parse_issue.py << 'EOF'
          import json
          import sys
          import re

          # Read the issue body
          with open('issue.json', 'r') as f:
              data = json.load(f)
              body = data['body']

          print(f"RAW BODY: {body}")
          print("---")

          # Extract fields using simple string operations
          lines = body.split('\n')
          channel_name = ""
          youtube_url = ""
          fully_forked = ""
          socials_raw = ""

          i = 0
          while i < len(lines):
              line = lines[i].strip()
              
              if line == "### Channel Name":
                  i += 1
                  # Skip empty lines
                  while i < len(lines) and lines[i].strip() == "":
                      i += 1
                  if i < len(lines) and not lines[i].startswith("###"):
                      channel_name = lines[i].strip()
                      
              elif line == "### YouTube URL":
                  i += 1
                  # Skip empty lines
                  while i < len(lines) and lines[i].strip() == "":
                      i += 1
                  if i < len(lines) and not lines[i].startswith("###"):
                      youtube_url = lines[i].strip()
                      
              elif line == "### Fully Forked?":
                  i += 1
                  # Skip empty lines
                  while i < len(lines) and lines[i].strip() == "":
                      i += 1
                  if i < len(lines) and not lines[i].startswith("###"):
                      fully_forked = lines[i].strip()
                      
              elif line == "### Socials (JSON, optional)":
                  i += 1
                  # Skip empty lines
                  while i < len(lines) and lines[i].strip() == "":
                      i += 1
                  if i < len(lines) and not lines[i].startswith("###"):
                      socials_raw = lines[i].strip()
              
              i += 1

          print(f"CHANNEL_NAME: '{channel_name}'")
          print(f"YOUTUBE_URL: '{youtube_url}'")
          print(f"FULLY_FORKED: '{fully_forked}'")
          print(f"SOCIALS_RAW: '{socials_raw}'")

          # Validate required fields
          if not channel_name or not youtube_url:
              print("ERROR: Missing required fields")
              sys.exit(1)

          # Extract channel ID from YouTube URL
          channel_id = ""
          if "channel/" in youtube_url:
              match = re.search(r'channel/([^/?]+)', youtube_url)
              if match:
                  channel_id = match.group(1)
          elif "@" in youtube_url:
              match = re.search(r'@([^/?]+)', youtube_url)
              if match:
                  channel_id = match.group(1)

          print(f"CHANNEL_ID: '{channel_id}'")

          if not channel_id:
              print(f"ERROR: Could not extract channel ID from URL: {youtube_url}")
              sys.exit(1)

          # Normalize fully_forked value
          fully_forked_bool = fully_forked.lower() == "true"

          # Parse socials
          socials = {
              "twitter": {
                  "url": "",
                  "visible": False
              },
              "website": {
                  "url": "",
                  "visible": True
              },
              "bluesky": {
                  "url": "",
                  "visible": False
              },
              "instagram": {
                  "url": "",
                  "visible": False
              },
              "youtube": {
                  "url": youtube_url,
                  "visible": True
              }
          }

          # Try to parse custom socials if provided
          if socials_raw and socials_raw != "_No response_":
              try:
                  custom_socials = json.loads(socials_raw)
                  # Merge custom socials with default structure
                  for platform, url in custom_socials.items():
                      if platform in socials:
                          socials[platform]["url"] = url
                          socials[platform]["visible"] = True
                      else:
                          # Add new platform
                          socials[platform] = {
                              "url": url,
                              "visible": True
                          }
              except json.JSONDecodeError:
                  print(f"WARNING: Could not parse socials JSON: {socials_raw}")
                  print("Using default socials structure")

          # Create new entry
          new_entry = {
              "channelId": channel_id,
              "name": channel_name,
              "FullyForked": fully_forked_bool,
              "socials": socials
          }

          print(f"NEW_ENTRY: {json.dumps(new_entry, indent=2)}")

          # Save to file
          with open('new_entry.json', 'w') as f:
              json.dump(new_entry, f, indent=2)

          print("Successfully created new_entry.json")
          EOF

          # Run the parser
          python3 parse_issue.py

          # Update channels.json
          CHANNEL_ID=$(jq -r .channelId new_entry.json)
          
          # Check if channel already exists
          if jq -e --arg channelId "$CHANNEL_ID" '.[] | select(.channelId == $channelId)' data/channels.json > /dev/null; then
            echo "Channel already exists, updating..."
            jq --argjson new "$(cat new_entry.json)" --arg channelId "$CHANNEL_ID" 'map(if .channelId == $channelId then $new else . end)' data/channels.json > data/channels.json.new
          else
            echo "Adding new channel..."
            jq '. + [input]' data/channels.json new_entry.json > data/channels.json.new
          fi
          mv data/channels.json.new data/channels.json

      - name: Commit and create PR
        uses: peter-evans/create-pull-request@v6
        with:
          commit-message: "Add/update channel from issue #${{ github.event.issue.number }}"
          title: "Add/update channel from issue #${{ github.event.issue.number }}"
          body: "This PR was auto-generated from an accepted issue."
          branch: "auto/channel-update-${{ github.event.issue.number }}"
          base: main

      - name: Comment on issue
        run: gh issue comment ${{ github.event.issue.number }} --body "A pull request has been created to update channels.json!"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
